<!DOCTYPE article PUBLIC "-//NLM//DTD Journal Archiving and Interchange DTD v2.3 20070202//EN" "archivearticle.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">Biomed Eng Online</journal-id><journal-title>BioMedical Engineering OnLine</journal-title><issn pub-type="epub">1475-925X</issn><publisher><publisher-name>BioMed Central</publisher-name><publisher-loc>London</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">15777475</article-id><article-id pub-id-type="pmc">1079899</article-id><article-id pub-id-type="publisher-id">1475-925X-4-19</article-id><article-id pub-id-type="doi">10.1186/1475-925X-4-19</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research</subject></subj-group></article-categories><title-group><article-title>Non-rigid registration of a 3D ultrasound and a MR image data set of the female pelvic floor using a biomechanical model</article-title></title-group><contrib-group><contrib id="A1" corresp="yes" contrib-type="author"><name><surname>Verhey</surname><given-names>Janko F</given-names></name><xref ref-type="aff" rid="I1">1</xref><email>verhey@med.uni-goettingen.de</email></contrib><contrib id="A2" contrib-type="author"><name><surname>Wisser</surname><given-names>Josef</given-names></name><xref ref-type="aff" rid="I2">2</xref><email>Josef.Wisser@fhk.usz.ch</email></contrib><contrib id="A3" contrib-type="author"><name><surname>Warfield</surname><given-names>Simon K</given-names></name><xref ref-type="aff" rid="I3">3</xref><email>warfield@bwh.harvard.edu</email></contrib><contrib id="A4" contrib-type="author"><name><surname>Rexilius</surname><given-names>Jan</given-names></name><xref ref-type="aff" rid="I4">4</xref><email>rexilius@mevis.de</email></contrib><contrib id="A5" contrib-type="author"><name><surname>Kikinis</surname><given-names>Ron</given-names></name><xref ref-type="aff" rid="I3">3</xref><email>kikinis@bwh.harvard.edu</email></contrib></contrib-group><aff id="I1"><label>1</label>Department of Medical Informatics, University Hospital Goettingen, Germany</aff><aff id="I2"><label>2</label>Department of Obstetrics, University Hospital Zuerich, Switzerland</aff><aff id="I3"><label>3</label>Surgical Planning Laboratory, Department of Radiology, Brigham and Women's Hospital, Boston, USA</aff><aff id="I4"><label>4</label>MeVis &#x02013; Center for Medical Diagnostic Systems and Visualization, Bremen, Germany</aff><pub-date pub-type="collection"><year>2005</year></pub-date><pub-date pub-type="epub"><day>18</day><month>3</month><year>2005</year></pub-date><volume>4</volume><fpage>19</fpage><lpage>19</lpage><ext-link ext-link-type="uri" xlink:href="http://www.biomedical-engineering-online.com/content/4/1/19"/><history><date date-type="received"><day>4</day><month>1</month><year>2005</year></date><date date-type="accepted"><day>18</day><month>3</month><year>2005</year></date></history><permissions><copyright-statement>Copyright &#x000a9; 2005 Verhey et al; licensee BioMed Central Ltd.</copyright-statement><copyright-year>2005</copyright-year><copyright-holder>Verhey et al; licensee BioMed Central Ltd.</copyright-holder><license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/2.0"><p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/2.0"/>), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.</p><!--<rdf xmlns="http://web.resource.org/cc/" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#" xmlns:dc="http://purl.org/dc/elements/1.1" xmlns:dcterms="http://purl.org/dc/terms"><Work xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:dcterms="http://purl.org/dc/terms/" rdf:about=""><license rdf:resource="http://creativecommons.org/licenses/by/2.0"/><dc:type rdf:resource="http://purl.org/dc/dcmitype/Text"/><dc:author>
               Verhey
               F
               Janko
               
               verhey@med.uni-goettingen.de
            </dc:author><dc:title>
            Non-rigid registration of a 3D ultrasound and a MR image data set of the female pelvic floor using a biomechanical model
         </dc:title><dc:date>2005</dc:date><dcterms:bibliographicCitation>BioMedical Engineering OnLine 4(1): 19-. (2005)</dcterms:bibliographicCitation><dc:identifier type="sici">1475-925X(2005)4:1&#x0003c;19&#x0003e;</dc:identifier><dcterms:isPartOf>urn:ISSN:1475-925X</dcterms:isPartOf><License rdf:about="http://creativecommons.org/licenses/by/2.0"><permits rdf:resource="http://web.resource.org/cc/Reproduction" xmlns=""/><permits rdf:resource="http://web.resource.org/cc/Distribution" xmlns=""/><requires rdf:resource="http://web.resource.org/cc/Notice" xmlns=""/><requires rdf:resource="http://web.resource.org/cc/Attribution" xmlns=""/><permits rdf:resource="http://web.resource.org/cc/DerivativeWorks" xmlns=""/></License></Work></rdf>--></license></permissions><abstract><sec><title>Background</title><p>The visual combination of different modalities is essential for many medical imaging applications in the field of Computer-Assisted medical Diagnosis (CAD) to enhance the clinical information content. Clinically, incontinence is a diagnosis with high clinical prevalence and morbidity rate. The search for a method to identify risk patients and to control the success of operations is still a challenging task. The conjunction of magnetic resonance (MR) and 3D ultrasound (US) image data sets could lead to a new clinical visual representation of the morphology as we show with corresponding data sets of the female anal canal with this paper.</p></sec><sec sec-type="methods"><title>Methods</title><p>We present a feasibility study for a non-rigid registration technique based on a biomechanical model for MR and US image data sets of the female anal canal as a base for a new innovative clinical visual representation.</p></sec><sec><title>Results</title><p>It is shown in this case study that the internal and external sphincter region could be registered elastically and the registration partially corrects the compression induced by the ultrasound transducer, so the MR data set showing the native anatomy is used as a frame for the US data set showing the same region with higher resolution but distorted by the transducer</p></sec><sec><title>Conclusion</title><p>The morphology is of special interest in the assessment of anal incontinence and the non-rigid registration of normal clinical MR and US image data sets is a new field of the adaptation of this method incorporating the advantages of both technologies.</p></sec></abstract></article-meta></front><body><sec><title>Background</title><p>In a recent study the advances of 3D sonographical imaging techniques to allow a sophisticated study of anal sphincter and levator ani muscle anatomy were described [<xref ref-type="bibr" rid="B1">1</xref>]. Today's common US examiniation techniques using a 7.5 MHz transducer allow a spatial resolution of up to 0.3 mm in each direction [<xref ref-type="bibr" rid="B2">2</xref>,<xref ref-type="bibr" rid="B3">3</xref>], whereas it is hard to obtain good quality MR images better than 1 mm in a single direction, when imaging the pelvis. Nevertheless, MR is a well established 3D data acquisition technique, which is used as gold standard to describe human anatomy in vivo.</p><p>It is a clinical necessity to enhance the information contained in imaging for diagnostic and also therapeutic purposes. In the past this led to new imaging techniques (visual representations) which use the information of at least two modalities in order to maximize the benefit for the clinician in diagnosis and treatment [<xref ref-type="bibr" rid="B4">4</xref>]. The registration of MR and US is of special interest because sonography is a diagnostic technique which is easy to handle, widely available, and furthermore economic [<xref ref-type="bibr" rid="B5">5</xref>]. To combine the best of the two worlds we will show that it is possible to match 3D MR and US for the assessment of female pelvic floor morphology.</p><p>Both introitus sonography and endoanal sonography focus on rectum and anal sphincter muscle morphology [<xref ref-type="bibr" rid="B6">6</xref>,<xref ref-type="bibr" rid="B7">7</xref>]. A recent publication by Williams et al. [<xref ref-type="bibr" rid="B8">8</xref>] shows a good correlation of endosonographic anatomy with endocoil MR. In contrast to this paper, our case shows the anatomy in a native physiologic state without stretching the tissue with a transrectal probe. No results have been published so far about the combination of introitus sonography and MRI using a standard bodyflex coil used for clinical purposes showing the anatomy in native status.</p><p>Because the organs in pelvic floor area are movable in position and size, consequently, new imaging techniques in this region should be based on non-rigid registration techniques (techniques considering tissue deformations) rather than on rigid registration techniques [<xref ref-type="bibr" rid="B9">9</xref>-<xref ref-type="bibr" rid="B11">11</xref>] in order to find the relationship of corresponding data set points. Actually, few cases of non-rigid MR and US image registration in the pelvic floor area are reported (e.g. for the treatment of prostate cancer by Mizowaki et al. [<xref ref-type="bibr" rid="B12">12</xref>]).</p><p>Non-rigid registration has become a fundamental method for medical image analysis during the past years [<xref ref-type="bibr" rid="B5">5</xref>,<xref ref-type="bibr" rid="B13">13</xref>-<xref ref-type="bibr" rid="B15">15</xref>,<xref ref-type="bibr" rid="B35">35</xref>] and is tested and approved with data from different anatomical regions [<xref ref-type="bibr" rid="B15">15</xref>-<xref ref-type="bibr" rid="B18">18</xref>]. An important issue in the registration process is the generation of deformation fields that reflect the transformation of an image in a realistic way with respect to the given anatomy [<xref ref-type="bibr" rid="B19">19</xref>,<xref ref-type="bibr" rid="B20">20</xref>]. Various physically based elastic models and algorithms have been recently described [<xref ref-type="bibr" rid="B21">21</xref>-<xref ref-type="bibr" rid="B24">24</xref>]. The aim of this paper is to apply an advanced algorithm previously approved for computer-assisted neurosurgery [<xref ref-type="bibr" rid="B25">25</xref>] and tested in corresponding head-neck data sets [<xref ref-type="bibr" rid="B26">26</xref>] now for registration purposes in the pelvic floor area, especially of the anal canal region to create a new visual representation.</p><p>Information derived from this type of image registration could lead towards new diagnostic (or even therapeutic) methods in the treatment of female pelvic floor dysfunctions using the MR data as a frame for high-resolution US data.</p></sec><sec sec-type="materials|methods"><title>Materials and methods</title><p>For our case report two corresponding 3D data sets (MR and US) of a women attending the outpatient clinics for diagnosis and treatment of urinary incontinence were taken with no specific clinical preference out of an ongoing study.</p><p>The 3D volume data set was acquired using Voluson 530 D, Kretztechnik, Zipf, Austria as it has been previously described [<xref ref-type="bibr" rid="B1">1</xref>]. The volume data set of the undistended anal sphincter and levator ani muscle was taken with a 7.5 MHz transvaginal probe (opening angle of 105&#x000b0; in tranversal and of 100&#x000b0; in longitudinal direction, isotropic resolution of 0.3 mm in each spatial direction) was placed at the posterior frenulum of labia minora.</p><p>The MR examination was carried out in sitting position with an 0.5T open configuration MR system, Signa SP GEMS, using a bodyflex surface coil for data acquisition. After a locator sequence, axial and sagittal T2-weighted fast-spin-echo sequences (TR 4000, TE 100, Matrix 256 &#x000d7; 256, slice thickness 7.2 mm, intersection gap 1.2 mm) were acquired and stored in DICOM format. The resolution in the matrix is 1.09 mm, whereby the MR data sets result to be non-isotropic in the three directions in space in contrast to the sonographical data sets having isotropic voxel size.</p><p>As a base system for both alignment and visualization we used the 3D-Slicer 2 software available free for non-profit organizations on both standard MS Windows platforms and Sun Solaris 5.8 Workstations [<xref ref-type="bibr" rid="B27">27</xref>-<xref ref-type="bibr" rid="B29">29</xref>]. The 3D Slicer software is designed for both diagnostical visualization and surgical planning, and it integrates several facets of image-guided medicine into a single environment: It provides capabilities for (I) automatic registration (aligning data sets), (II) semi-automatic segmentation, (III) generation of 3D surface models (for viewing the segmented structures), (IV) 3D visualization, and (V) quantitative analysis (measuring distances, angles, surface areas, and volumes) of various medical scans.</p><p>The processing followed the strategy as described in Fig. <xref ref-type="fig" rid="F1">1</xref>. After carrying out an edge enhancement in the 3D US data set using adaptive filter techniques [<xref ref-type="bibr" rid="B30">30</xref>,<xref ref-type="bibr" rid="B31">31</xref>] both datasets were initially aligned using the standard 3D-Slicer's fiducial alignment method by placing three landmarks as fiducials in two different axial slices of both axial MR and US data set. We chose the mucosa and points in the internal or the external sphincter muscle as anatomical landmarks for the rigid overlay assuming the MR images to be the gold standard for the muscle components [<xref ref-type="bibr" rid="B8">8</xref>]. As a result an affine transformation matrix was determinded for the overlay. Both data sets were cropped to the region of interest (Fig. <xref ref-type="fig" rid="F3">3</xref>) to minimize the calculation time. After resampling using a standard linear interpolation method both data sets have an isotropic resolution of 0.6 mm in each spatial direction. The worst registration errors of the correlation ratio are due to the MR resolution [<xref ref-type="bibr" rid="B32">32</xref>,<xref ref-type="bibr" rid="B33">33</xref>]. We carried out a visual assessment of the accuracy of the registration and assumed the error for each modality to be of the order of half a voxel size in our case [<xref ref-type="bibr" rid="B34">34</xref>]. The entire processing time for the process shown in Fig. <xref ref-type="fig" rid="F1">1</xref> for this feasibility study was one hour not considering the data acquisition times for MR and US.</p><fig position="float" id="F1"><label>Figure 1</label><caption><p><bold>Strategy to register</bold>. Strategy to register MR and 3D ultrasound image data sets. Solid lines display the strategy shown in this paper. Dashed lines symbolize optional ways which were followed but which show no further relevant and new details. The symbols on the right refer to the format of the data sets: The series of squares stands for a series of parallel slices and the cube is for a volume block format.</p></caption><graphic xlink:href="1475-925X-4-19-1"/></fig><fig position="float" id="F3"><label>Figure 3</label><caption><p><bold>MR data with aligned sonographical data</bold>. Shown are the corresponding MR data set of the pelvic floor to the US data set from Fig. 2. (a) shows the axial plane from the axial data set; (b) and (c) show the sagittal respectively coronal plane from the corresponding sagittal data set. (c) is shown only for illustration purposes due to the poor resolution. On the right side the original MR data set is shown and on the left side a cutout with the corresponding initial alignment. The capital letters indicate anatomical structures: A: anal region; B: bladder; C: coccyx; F: ischial tuberosity; L: lumbar vertebrae; S: symphysis; V: vaginal region.</p></caption><graphic xlink:href="1475-925X-4-19-3"/></fig><p>In this work we present the application of an algorithm for non-rigid registration described previously by two of the authors [<xref ref-type="bibr" rid="B19">19</xref>,<xref ref-type="bibr" rid="B20">20</xref>]. This algorithm was originally developed for MR techniques and we applied it for new anatomical region assuming that the edge enhancement algorithms are valid for US data sets, too. In order to obtain realistic deformations, we propose a physics-based elastic model. The method does not require segmentation and does not have the drawback that initial estimates of the deformation are only generated for the boundary of a considered structure. Instead, these estimates are calculated based on a template matching approach with a local similarity measure. Furthermore, we incorporated different models for elasticities into our algorithm. The discretization of the underlying equation is done by a finite element technique, which has become a popular method for medical imaging applications [<xref ref-type="bibr" rid="B24">24</xref>,<xref ref-type="bibr" rid="B25">25</xref>].</p><p>The registration process can be described as an optimization problem. Target of the optmization is the minimization of the deformation energy between two data sets, reference and template. The displacement field which describes the correlation of corresponding anatomical structures in both image data sets can be described using the theorema of minimal potential enegy E. With this in a volume &#x003a9; a deformation u needs to be determined which minimizes the following equation.</p><p><inline-graphic xlink:href="1475-925X-4-19-i1.gif"/></p><p>F means the external force causing the deformation u. &#x003c3; is the stress which causes the (local) distortion &#x003b5;. The relationship between &#x003c3; and &#x003b5; can be described using elastomechanical equation &#x003c3; = D&#x003b5; with D being an elasticity tensor. Due to the fact that in the dedicated anatomical region mostly muscle tissue is found, the tissue parameter in D used in the biomechanical model is assumed to be homogeneous (according to [<xref ref-type="bibr" rid="B20">20</xref>,<xref ref-type="bibr" rid="B22">22</xref>]and[<xref ref-type="bibr" rid="B25">25</xref>]). The minimization of the potential energy E then is the registration process devided in two basic steps. The method is described in detail in [<xref ref-type="bibr" rid="B20">20</xref>].</p></sec><sec><title>Results</title><p>Leading structures in both of our data sets are the rectum and the anal canal with the mucosa, the circular as well as the conjoined longitudinal muscle layer of the anorectal junction and the levator ani muscle, especially the puborectalis muscle. These morphological structures can be identified clearly in US as well as in MR images &#x02013; in the latter case with much less contrast than in the US data sets. In addition to this MR shows up the pelvic bones and skin surface facilitates spatial orientation.</p><p>The application of adaptive filtering on US data set increased the signal to noise ratio significantly. As a consequence edges appear enhanced in the filtered images showing therefore the anatomical details much clearer. This is shown in Fig. <xref ref-type="fig" rid="F2">2</xref>. Both external and internal anal sphincter muscle as well as the anal mucosa can be identified in filtered images. Especially, the internal anal sphincter muscle appears clearly as a hypoechogenic region. The levator ani muscle has a V-form surrounding the external anal sphincter muscle best visible in the axial plane. It can be easily distinguished from the hyperechogenic tissue of the external anal sphincter.</p><fig position="float" id="F2"><label>Figure 2</label><caption><p><bold>Sonographical data</bold>. Sonographical documentation method for examination of the pelvic floor in analogon to the usual used MR nomenclature [36, 37]. Shown is the filtered US data set: (a) axial, (left side: not filtered to show the enhancement induced by filtering) (b) sagittal and (c) coronal plane through the anal canal. A: the internal anal sphincter muscle; B: the external anal sphincter muscle (levator ani muscle); C: anal canal mucosa; D: rectum.</p></caption><graphic xlink:href="1475-925X-4-19-2"/></fig><p>Fig. <xref ref-type="fig" rid="F3">3</xref> (left side) shows the MR data set analog to the US images in Fig. <xref ref-type="fig" rid="F2">2</xref> in its different planes. In the right side of Fig. <xref ref-type="fig" rid="F3">3</xref> the position and the size of the overlayed US data set and the spatial orientation in the MR data set is shown. Due to the higher resolution of the US data set about three times more data points are visible in the overlay region in comparision to the MR image significantly magnifying the overlay region. Fig. <xref ref-type="fig" rid="F3">3b</xref> shows the sagittal plane of the MR data set. Few structures are distinguishable clearly in the vaginal and anal region due to the poor resolution and contrast. Even filter techniques could not significantly increase the contrast in this region in sagittal scan and are not shown therefore.</p><p>In Fig. <xref ref-type="fig" rid="F4">4</xref> the registration is explicitly shown for one axial plane. The top of each image indicates the anterior direction. MR is used as the template and US as the reference image. As a result the US data set is displayed in the coordinates of the MR due to the application of the deformation field (Fig. <xref ref-type="fig" rid="F4">4c</xref>). At the position of the transducer &#x02013; best visible in the top of Fig. <xref ref-type="fig" rid="F4">4a</xref> &#x02013; the displacement field shows major differences. The compression induced with the transducer head is partially corrected in the registered image Fig. <xref ref-type="fig" rid="F4">4c</xref>. The displacement field in z-direction perpendicular to the axial slice is ommited due to the poor resolution of the MR data set in this direction and due to the fact that in sagittal planes too few anatomical landmarks could be identified clearly.</p><fig position="float" id="F4"><label>Figure 4</label><caption><p><bold>Registration and displacement field</bold>. Axial plane through non-rigid registration of the anal canal: Original data are shown in (a) and (d) &#x02013; US and MR image, respectively. For simplification of visualization only the difference components in x-direction (b left) and in y-direction (b right) are shown. The difference in z-direction is ommited. (e) shows the difference image of (a) and (d) together with the difference components in x direction (e left) and in y direction (e right). (c) shows the registered image after the application of the displacement field.</p></caption><graphic xlink:href="1475-925X-4-19-4"/></fig><p>The non-rigid registration qualifies the visual assessment in axial plane very well. An estimation of accuracy in both sagittal and coronal plane could be quantified not better than half a voxel size. In Fig. <xref ref-type="fig" rid="F5">5</xref> the segmentation of the internal anal sphincter muscle is explicitly shown in one axial plane. Analogous to Fig. <xref ref-type="fig" rid="F4">4</xref> the top of each image indicates the anterior direction. It is shown for the MR (Fig. <xref ref-type="fig" rid="F5">5a</xref>), the US (Fig. <xref ref-type="fig" rid="F5">5b</xref>) and the registered image (Fig. <xref ref-type="fig" rid="F5">5c</xref>) respectively. The deformation induced by the ultrasound probe placed in anterior position is corrected (Fig. <xref ref-type="fig" rid="F5">5d</xref>).</p><fig position="float" id="F5"><label>Figure 5</label><caption><p><bold>Segmentation of the internal anal sphincter muscle</bold>. Segmentation of the internal anal sphincter muscle. (a) shows the original axial MR slice with the contour of the internal anal sphincter muscle in pink color, (b) the corresponding US slice with the contour in green color and (c) the registered image with the contour in blue color respectively. (d) shows the areas in comparision. The arrows indicate where the contour of the internal anal sphincter muscle is modified with the algorithm. The registration partially corrects the compression induced by the transducer (the upper arrow shows the position of the transducer).</p></caption><graphic xlink:href="1475-925X-4-19-5"/></fig></sec><sec><title>Discussion</title><p>MR leads to rigid non-deformed data sets in contrast to most sonographical data acquisition techniques. The better structural contrast of the MR data sets allows a better spacial orientation but the quality and resolution especially for soft tissue is higher with 3D US techniques.</p><p>Due to several factors such as the lack of image structure, the poor signal to noise ratio of the MR data set, the intensity artifacts, the computational complexity and the restricted time frame it is not feasible to quantify the deformation occurring between each voxel of the corresponding data sets directly. Consequently, we chose a physics-based non-rigid registration algorithm to estimate a deformation field only at sparse locations which have to be interpolated throughout the image. Models of this type have become popular for non-rigid registration because they are fast and have the potential to constrain the underlying deformation in a plausible manner.</p><p>Included in our method is an edge enhancement for the US data set using adaptive filtering. Our sophisticated 3D filter technique requires an isotropic or at least a nearly isotropic resolution of the volume image data sets which is the case for our US data set. Furthermore, most registration methods require to have similar resolution of both images, similar regions with the same image size and only local deformations on a short range scale. Therefore, nevertheless, preprocessing steps were needed. Corresponding clinical data sets of two different modalities usually fail fulfilling those preconditions completely &#x02013; so do ours.</p><p>For initial alignment purposes it helps to localize the anatomy. This is demonstrated in Fig. <xref ref-type="fig" rid="F2">2</xref>. The difference of resolution in MR's axial direction in comparison to the resolution of ultrasound is huge. Due to this, a misplacement of ultrasound's axial slices in relationship with MR axial slices was of no initial relevance and our error in misalignment assumed to be in the region of half a voxel size in each spatial direction.</p><p>Fig. <xref ref-type="fig" rid="F3">3</xref> shows the poor resolution and contrast in the vaginal and anal region of the MR data sets. Few structures are distinguishable clearly in this region. Even filter techniques could not significantly increase the contrast in this region in sagittal scan and are not shown therefore. This leads to the wish to enhance the clinical information in this region using registration techniques as presented with this paper.</p><p>MR and US show minor contour differences for all the anatomical structures. The reason for this misplacement is based on the two completely different data acquisition techniques. Even if they were very carefully carried out the prevention of any distortion is impossible and leads to the following effects: 1. The coupling of the transducer to the tissue induces a tissue deformation in any case. 2. The position of the patient varies without placing any external markers if the data acquisition takes place at different places and different times. 3. Different acquisition times induce e.g. different filling levels of the organs with different contours as a result.</p><p>The registration results shown in Fig. <xref ref-type="fig" rid="F4">4</xref> and Fig. <xref ref-type="fig" rid="F5">5</xref> demonstrate clearly the feasibility of the non-rigid registration method for the correspondent 3D data sets of the anal canal. The native MR data set is used as a frame for the US data set &#x02013; which shows the sphincter structures more clearly than the MR.</p><p>The levator ani muscle cannot be registered with accuracy because the identification in the US data set due to the poor contrast needs an experienced clinician and results impossible for an automated algorithm. The visual representation is limited to slightly distorted tissue structures as proved with this data and shown before in previous attempts in corresponding head-neck data sets. But regions with high contrast and slight deformations can be registered using our method. For further studies MR data sets with higher resolution MR and isotropic voxel size would be desirable.</p></sec><sec><title>Conclusion</title><p>The present case report shows the feasibility of the visual representation presented for normal clinical data of the anal canal. The registration partially corrects the compression induced by the transducer, so the MR data set showing the native anatomy is used as a frame for the US data set showing the same region with higher resolution but distorted by the transducer. As a consequence the clinical information for diagnostic purposes is enhanced for resolution (Fig. <xref ref-type="fig" rid="F3">3</xref>) and for position (Fig. <xref ref-type="fig" rid="F5">5</xref>).</p><p>Obviously, these findings need to be validated with more cases in a future prospective study. As previously emphazised the MR images were assumed to be the gold standard for the contours. Using the non-rigid registration technique described in this paper and developing a more sophisticated data acquisition and registering technique this might be changed in the future and the application of 3D ultrasound (US) has a high potential in the innovative development of future low-cost applications.</p></sec><sec><title>Authors' contributions</title><p>JFV developed the registration strategy and did the technical part implementing the visual representation method described here. JW did the data acquisition and the medical part. SKW and JR developed the used linear elastic model and helped to modify and adapt it to the present data. RK provided the computing infrastructure and consulted the development process of the method. All authors read and approved the final manuscript.</p></sec></body><back><ack><sec><title>Acknowledgements</title><p>This work was supported by the Deutsche Forschungsgemeinschaft (DFG = German Research Foundation), grant VE 239/3-1, and of the NIH, grants P4 RR13218 and P01 CA67165.</p><p>Special thanks go to Prof. R. Kubik-Huch, MD, Department of Radiology, Kantonsspital Baden, Switzerland, for providing the MR data set.</p></sec></ack><ref-list><ref id="B1"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Wisser</surname><given-names>J</given-names></name><name><surname>Schaer</surname><given-names>GN</given-names></name><name><surname>Kurmanavicius</surname><given-names>J</given-names></name><name><surname>Huch</surname><given-names>R</given-names></name><name><surname>Huch</surname><given-names>A</given-names></name></person-group><article-title>Use of 3D ultrasound as a new approach to assess obstetrical trauma to the pelvic floor</article-title><source>Ultraschall Med</source><year>1999</year><volume>20</volume><fpage>15</fpage><lpage>18</lpage><pub-id pub-id-type="pmid">10226341</pub-id><pub-id pub-id-type="doi">10.1055/s-1999-14226</pub-id></citation></ref><ref id="B2"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Gladisch</surname><given-names>R</given-names></name></person-group><source>Praxis der abdominellen Ultraschalldiagnostik</source><year>1992</year><edition>2., &#x000fc;berarb. und erg. Aufl</edition><publisher-name>Schattauer &#x02013; Stuttgart, New York</publisher-name></citation></ref><ref id="B3"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Trautwein</surname><given-names>A</given-names></name><name><surname>Kreibig</surname><given-names>U</given-names></name><name><surname>Oberhausen</surname><given-names>E</given-names></name><name><surname>H&#x000fc;ttermann</surname><given-names>J</given-names></name></person-group><person-group person-group-type="editor"><name><surname>de Gruyter</surname></name></person-group><source>Physik f&#x000fc;r Mediziner, Biologen, Pharmazeuten</source><year>1999</year><edition>5</edition><publisher-name>Berlin-New York</publisher-name></citation></ref><ref id="B4"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Jolesz</surname><given-names>FA</given-names></name><name><surname>Nabavi</surname><given-names>A</given-names></name><name><surname>Kikinis</surname><given-names>R</given-names></name></person-group><article-title>Integration of interventional MRI with computer-assisted surgery</article-title><source>J Magn Reson Imaging</source><year>2001</year><volume>13</volume><fpage>69</fpage><lpage>77</lpage><pub-id pub-id-type="pmid">11169806</pub-id><pub-id pub-id-type="doi">10.1002/1522-2586(200101)13:1&#x0003c;69::AID-JMRI1011&#x0003e;3.0.CO;2-2</pub-id></citation></ref><ref id="B5"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Bucholz</surname><given-names>RD</given-names></name><name><surname>Smith</surname><given-names>KR</given-names></name><name><surname>Laycock</surname><given-names>KA</given-names></name><name><surname>McDurmont</surname><given-names>LL</given-names></name></person-group><article-title>Three-dimensional localization: from image-guided surgery to information-guided therapy</article-title><source>Methods</source><year>2001</year><volume>25</volume><fpage>186</fpage><lpage>200</lpage><pub-id pub-id-type="pmid">11812205</pub-id><pub-id pub-id-type="doi">10.1006/meth.2001.1234</pub-id></citation></ref><ref id="B6"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Peschers</surname><given-names>UM</given-names></name><name><surname>DeLancey</surname><given-names>JO</given-names></name><name><surname>Schaer</surname><given-names>GN</given-names></name><name><surname>Schuessler</surname><given-names>B</given-names></name></person-group><article-title>Exoanal ultrasound of the anal sphincter: normal anatomy and sphincter defects</article-title><source>Br J Obstet Gynaecol</source><year>1997</year><volume>104</volume><fpage>999</fpage><lpage>1003</lpage><pub-id pub-id-type="pmid">9307524</pub-id></citation></ref><ref id="B7"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Nielsen</surname><given-names>MB</given-names></name><name><surname>Pedersen</surname><given-names>JF</given-names></name><name><surname>Hauge</surname><given-names>C</given-names></name><name><surname>Rasmussen</surname><given-names>OO</given-names></name><name><surname>Christiansen</surname><given-names>J</given-names></name></person-group><article-title>Endosonography of the anal sphincter: findings in healthy volunteers</article-title><source>AJR Am J Roentgenol</source><year>1991</year><volume>157</volume><fpage>1199</fpage><lpage>1202</lpage><pub-id pub-id-type="pmid">1950865</pub-id></citation></ref><ref id="B8"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Williams</surname><given-names>AB</given-names></name><name><surname>Bartram</surname><given-names>CI</given-names></name><name><surname>Halligan</surname><given-names>S</given-names></name><name><surname>Marshall</surname><given-names>MM</given-names></name><name><surname>Nicholls</surname><given-names>RJ</given-names></name><name><surname>Kmiot</surname><given-names>WA</given-names></name></person-group><article-title>Endosonographic anatomy of the normal anal canal compared with endocoil magnetic resonance imaging</article-title><source>Dis Colon Rectum</source><year>2002</year><volume>45</volume><fpage>176</fpage><lpage>183</lpage><pub-id pub-id-type="pmid">11852329</pub-id><pub-id pub-id-type="doi">10.1007/s10350-004-6140-1</pub-id></citation></ref><ref id="B9"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Roche</surname><given-names>A</given-names></name><name><surname>Pennec</surname><given-names>X</given-names></name><name><surname>Malandain</surname><given-names>G</given-names></name><name><surname>Ayache</surname><given-names>N</given-names></name></person-group><article-title>Rigid registration of 3-D ultrasound with MR images: a new approach combining intensity and gradient information</article-title><source>IEEE Trans Med Imaging</source><year>2001</year><volume>20</volume><fpage>1038</fpage><lpage>1049</lpage><pub-id pub-id-type="pmid">11686439</pub-id><pub-id pub-id-type="doi">10.1109/42.959301</pub-id></citation></ref><ref id="B10"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>de Bruin</surname><given-names>PW</given-names></name><name><surname>Vos</surname><given-names>FM</given-names></name><name><surname>Post</surname><given-names>FH</given-names></name><name><surname>Vossepoel</surname><given-names>AM</given-names></name><name><surname>de Blok</surname><given-names>SB</given-names></name></person-group><article-title>Interactive matching of ultrasound and MRI for visualization during resection of myomata</article-title><source>SPIE Int Soc Opt Eng Proceedings of Spie the International Society for Optical Engineering</source><year>2002</year><volume>4681</volume><fpage>77</fpage><lpage>84</lpage></citation></ref><ref id="B11"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Pagoulatos</surname><given-names>N</given-names></name><name><surname>Haynor</surname><given-names>DR</given-names></name><name><surname>Kim</surname><given-names>Y</given-names></name></person-group><article-title>Image-based registration of ultrasound and magnetic resonance images: a preliminary study</article-title><source>SPIE Int Soc Opt Eng Proceedings of Spie the International Society for Optical Engineering</source><year>2000</year><volume>3976</volume><fpage>156</fpage><lpage>164</lpage></citation></ref><ref id="B12"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Mizowaki</surname><given-names>T</given-names></name><name><surname>Cohen</surname><given-names>GN</given-names></name><name><surname>Fung</surname><given-names>AYC</given-names></name><name><surname>Zaider</surname><given-names>M</given-names></name></person-group><article-title>Towards integrating functional imaging in the treatment of prostate cancer with radiation: The registration of the MR spectroscopy imaging to ultrasound/CT images and its implementation in treatment planning</article-title><source>Int J Radiat Oncol Biol Phys</source><year>2002</year><volume>54</volume><fpage>1558</fpage><lpage>1564</lpage><pub-id pub-id-type="pmid">12459385</pub-id><pub-id pub-id-type="doi">10.1016/S0360-3016(02)03805-1</pub-id></citation></ref><ref id="B13"><citation citation-type="other"><person-group person-group-type="author"><name><surname>Pennec</surname><given-names>X</given-names></name><name><surname>Ayache</surname><given-names>N</given-names></name><name><surname>Roche</surname><given-names>A</given-names></name><name><surname>Cachier</surname><given-names>P</given-names></name></person-group><article-title>Non-rigid MR/US registration for tracking brain deformations</article-title><source>Proceedings International Workshop on Medical Imaging and Augmented Reality IEEE Computer Soc</source><year>2001</year></citation></ref><ref id="B14"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Roche</surname><given-names>A</given-names></name></person-group><article-title>Interventional radiology in oncology</article-title><source>Bull Acad Natl Med</source><year>1991</year><volume>175</volume><fpage>1121</fpage><lpage>1127</lpage><pub-id pub-id-type="pmid">1809486</pub-id></citation></ref><ref id="B15"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Warfield</surname><given-names>SK</given-names></name><name><surname>Nabavi</surname><given-names>A</given-names></name><name><surname>Butz</surname><given-names>T</given-names></name><name><surname>Tuncali</surname><given-names>K</given-names></name><name><surname>Silverman</surname><given-names>SG</given-names></name><name><surname>Black</surname><given-names>PM</given-names></name><name><surname>Jolesz</surname><given-names>FA</given-names></name><name><surname>Kikinis</surname><given-names>R</given-names></name></person-group><article-title>Intraoperative segmentation and nonrigid registration for image guided therapy</article-title><source>Medical Image Computing and Computer Assisted Intervention MICCAI</source><year>2000</year><volume>1935</volume><fpage>176</fpage><lpage>185</lpage></citation></ref><ref id="B16"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Ruiz-Alzola</surname><given-names>J</given-names></name><name><surname>Westin</surname><given-names>CF</given-names></name><name><surname>Warfield</surname><given-names>SK</given-names></name><name><surname>Alberola</surname><given-names>C</given-names></name><name><surname>Maier</surname><given-names>S</given-names></name><name><surname>Kikinis</surname><given-names>R</given-names></name></person-group><article-title>Nonrigid registration of 3D tensor medical data</article-title><source>Med Image Anal</source><year>2002</year><volume>6</volume><fpage>143</fpage><lpage>161</lpage><pub-id pub-id-type="pmid">12045001</pub-id><pub-id pub-id-type="doi">10.1016/S1361-8415(02)00055-5</pub-id></citation></ref><ref id="B17"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Bharatha</surname><given-names>A</given-names></name><name><surname>Hirose</surname><given-names>M</given-names></name><name><surname>Hata</surname><given-names>N</given-names></name><name><surname>Warfield</surname><given-names>SK</given-names></name><name><surname>Ferrant</surname><given-names>M</given-names></name><name><surname>Zou</surname><given-names>KH</given-names></name><name><surname>Suarez-Santana</surname><given-names>E</given-names></name><name><surname>Ruiz-Alzola</surname><given-names>J</given-names></name><name><surname>D'Amico</surname><given-names>A</given-names></name><name><surname>Cormack</surname><given-names>RA</given-names></name><etal></etal></person-group><article-title>Evaluation of three-dimensional finite element-based deformable registration of pre- and intraoperative prostate imaging</article-title><source>Med Phys</source><year>2001</year><volume>28</volume><fpage>2551</fpage><lpage>2560</lpage><pub-id pub-id-type="pmid">11797960</pub-id><pub-id pub-id-type="doi">10.1118/1.1414009</pub-id></citation></ref><ref id="B18"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Butz</surname><given-names>T</given-names></name><name><surname>Warfield</surname><given-names>SK</given-names></name><name><surname>Tuncali</surname><given-names>K</given-names></name><name><surname>Silverman</surname><given-names>SG</given-names></name><name><surname>van Sonnenberg</surname><given-names>E</given-names></name><name><surname>Jolesz</surname><given-names>FA</given-names></name><name><surname>R</surname><given-names>K</given-names></name></person-group><article-title>Pre- and intra-operative planning and simulation of percutaneous tumor ablation</article-title><source>Medical Image Computing and Computer Assisted Intervention MICCAI</source><year>2000</year><volume>1935</volume><fpage>317</fpage><lpage>326</lpage></citation></ref><ref id="B19"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Warfield</surname><given-names>SK</given-names></name><name><surname>Talos</surname><given-names>F</given-names></name><name><surname>Tei</surname><given-names>A</given-names></name><name><surname>Bharatha</surname><given-names>A</given-names></name><name><surname>Nabavi</surname><given-names>A</given-names></name><name><surname>Ferrant</surname><given-names>M</given-names></name><name><surname>Black</surname><given-names>PM</given-names></name><name><surname>Jolesz</surname><given-names>FA</given-names></name><name><surname>Kikinis</surname><given-names>R</given-names></name></person-group><article-title>Real-time registration of volumetric brain MRI by biomechanical simulation of deformation during image guided neurosurgery</article-title><source>Computing &#x00026; Visualization in Science</source><year>2002</year><volume>5</volume><fpage>3</fpage><lpage>11</lpage><pub-id pub-id-type="doi">10.1007/s00791-002-0083-7</pub-id></citation></ref><ref id="B20"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Rexilius</surname><given-names>J</given-names></name><name><surname>Warfield</surname><given-names>SK</given-names></name><name><surname>Guttmann</surname><given-names>CRG.</given-names></name><name><surname>Wei</surname><given-names>X</given-names></name><name><surname>Benson</surname><given-names>R</given-names></name><name><surname>Wolfson</surname><given-names>L</given-names></name><name><surname>Shenton</surname><given-names>M</given-names></name><name><surname>Handels</surname><given-names>H</given-names></name></person-group><article-title>A Novel Nonrigid Registration Algorithm and Applications</article-title><source>Medical Image Computing and Computer Assisted Intervention MICCAI</source><year>2001</year><volume>1936</volume><fpage>923</fpage><lpage>931</lpage></citation></ref><ref id="B21"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Davatzikos</surname><given-names>C</given-names></name></person-group><article-title>Spatial transformation and registration of brain images using elastically deformable models</article-title><source>Computer Vision &#x00026; Image Understanding</source><year>1997</year><volume>66</volume><fpage>207</fpage><lpage>222</lpage><pub-id pub-id-type="pmid">11543561</pub-id><pub-id pub-id-type="doi">10.1006/cviu.1997.0605</pub-id></citation></ref><ref id="B22"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Ferrant</surname><given-names>M</given-names></name><name><surname>Nabavi</surname><given-names>A</given-names></name><name><surname>Macq</surname><given-names>B</given-names></name><name><surname>Jolesz</surname><given-names>FA</given-names></name><name><surname>Kikinis</surname><given-names>R</given-names></name><name><surname>Warfield</surname><given-names>SK</given-names></name></person-group><article-title>Registration of 3-D intraoperative MR images of the brain using a finite-element biomechanical model</article-title><source>IEEE Trans Med Imaging</source><year>2001</year><volume>20</volume><fpage>1384</fpage><lpage>1397</lpage><pub-id pub-id-type="pmid">11811838</pub-id><pub-id pub-id-type="doi">10.1109/42.974933</pub-id></citation></ref><ref id="B23"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Collins</surname><given-names>DL</given-names></name><name><surname>Peters</surname><given-names>TM</given-names></name><name><surname>Dai</surname><given-names>W</given-names></name><name><surname>Evans</surname><given-names>AC</given-names></name></person-group><article-title>Model based segmentation of individual brain structures from MRI data</article-title><source>SPIE Visualization in Biomedical Computing</source><year>1992</year><volume>1808</volume><fpage>10</fpage><lpage>23</lpage></citation></ref><ref id="B24"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Bro-Nielsen</surname><given-names>M</given-names></name></person-group><article-title>Finite element modeling in surgery simulation</article-title><source>Proceedings of the IEEE</source><year>1998</year><volume>86</volume><fpage>490</fpage><lpage>503</lpage><pub-id pub-id-type="doi">10.1109/5.662874</pub-id></citation></ref><ref id="B25"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Ferrant</surname><given-names>M</given-names></name><name><surname>Nabavi</surname><given-names>A</given-names></name><name><surname>Macq</surname><given-names>B</given-names></name><name><surname>Black</surname><given-names>PM</given-names></name><name><surname>Jolesz</surname><given-names>FA</given-names></name><name><surname>Kikinis</surname><given-names>R</given-names></name><name><surname>Warfield</surname><given-names>SK</given-names></name></person-group><article-title>Serial registration of intraoperative MR images of the brain</article-title><source>Med Image Anal</source><year>2002</year><volume>6</volume><fpage>337</fpage><lpage>359</lpage><pub-id pub-id-type="pmid">12426109</pub-id><pub-id pub-id-type="doi">10.1016/S1361-8415(02)00060-9</pub-id></citation></ref><ref id="B26"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Verhey</surname><given-names>JF</given-names></name><name><surname>Ludwig</surname><given-names>A</given-names></name><name><surname>Rexilius</surname><given-names>J</given-names></name><name><surname>Warfield</surname><given-names>SK</given-names></name><name><surname>Mamisch</surname><given-names>C</given-names></name><name><surname>Kikinis</surname><given-names>R</given-names></name><name><surname>Westin</surname><given-names>CF</given-names></name><name><surname>Seibel</surname><given-names>R</given-names></name><name><surname>Rienhoff</surname><given-names>O</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Meiler M, Saupe D, Kruggel F, Handels H, Lehmann T</surname></name></person-group><article-title>Mulitmodale nicht-rigide Registrierung von Ultraschall und MR Bilddaten unter Verwendung eines biomechanischen Modells</article-title><source>Bildverarbeitung f&#x000fc;r die Medizin 2002 &#x02013; Algorithmen Systeme Anwendungen</source><year>2002</year><publisher-name>Heidelberg: Springer</publisher-name><fpage>310</fpage><lpage>313</lpage></citation></ref><ref id="B27"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Gering</surname><given-names>D</given-names></name></person-group><article-title>A System for Surgical Planning and Guidance using Image Fusion and Interventional MR</article-title><source>Master's Thesis</source><year>1999</year><publisher-name>Cambridge: Massassuchets Institute of Technology</publisher-name></citation></ref><ref id="B28"><citation citation-type="other"><person-group person-group-type="author"><name><surname>Gering</surname><given-names>D</given-names></name><name><surname>Nabavi</surname><given-names>A</given-names></name><name><surname>Kikinis</surname><given-names>R</given-names></name><name><surname>Grimson</surname><given-names>WEL</given-names></name><name><surname>Hata</surname><given-names>N</given-names></name><name><surname>Everett</surname><given-names>P</given-names></name><name><surname>Jolesz</surname><given-names>F</given-names></name><name><surname>Wells</surname><given-names>W</given-names></name></person-group><article-title>An Integrated Visualization System for Surgical Planning and Guidance using Image Fusion and Interventional Imaging</article-title><source>Proceeding of Medical Image Computing and Computer-Assisted Intervention (MICCAI), Cambridge England, Sept 1999: 1999; Cambridge</source><year>1999</year><fpage>809</fpage><lpage>819</lpage></citation></ref><ref id="B29"><citation citation-type="other"><article-title>3D Slicer Software</article-title><comment><ext-link ext-link-type="uri" xlink:href="http://splweb.bwh.harvard.edu:8000"/> or <ext-link ext-link-type="uri" xlink:href="http://www.slicer.org"/></comment></citation></ref><ref id="B30"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Westin</surname><given-names>CF</given-names></name><name><surname>Richolt</surname><given-names>J</given-names></name><name><surname>Moharir</surname><given-names>V</given-names></name><name><surname>Kikinis</surname><given-names>R</given-names></name></person-group><article-title>Affine adaptive filtering of CT data</article-title><source>Med Image Anal</source><year>2000</year><volume>4</volume><fpage>161</fpage><lpage>177</lpage><pub-id pub-id-type="pmid">10972328</pub-id><pub-id pub-id-type="doi">10.1016/S1361-8415(00)00011-6</pub-id></citation></ref><ref id="B31"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Westin</surname><given-names>CF</given-names></name><name><surname>Wigstrom</surname><given-names>L</given-names></name><name><surname>Loock</surname><given-names>T</given-names></name><name><surname>Sjoqvist</surname><given-names>L</given-names></name><name><surname>Kikinis</surname><given-names>R</given-names></name><name><surname>Knutsson</surname><given-names>H</given-names></name></person-group><article-title>Three-dimensional adaptive filtering in magnetic resonance angiography</article-title><source>J Magn Reson Imaging</source><year>2001</year><volume>14</volume><fpage>63</fpage><lpage>71</lpage><pub-id pub-id-type="pmid">11436216</pub-id><pub-id pub-id-type="doi">10.1002/jmri.1152</pub-id></citation></ref><ref id="B32"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Roche</surname><given-names>A</given-names></name><name><surname>Pennec</surname><given-names>X</given-names></name><name><surname>Rudolph</surname><given-names>M</given-names></name><name><surname>Auer</surname><given-names>DP</given-names></name><name><surname>Malandain</surname><given-names>G</given-names></name><name><surname>Ourselin</surname><given-names>S</given-names></name><name><surname>Auer</surname><given-names>LM</given-names></name><name><surname>Ayache</surname><given-names>N</given-names></name></person-group><article-title>Generalized correlation ratio for rigid registration of 3D ultrasound with MR images</article-title><source>Medical Image Computing and Computer Assisted Intervention MICCAI</source><year>2000</year><volume>1935</volume><fpage>567</fpage><lpage>577</lpage></citation></ref><ref id="B33"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Pennec</surname><given-names>X</given-names></name><name><surname>Thirion</surname><given-names>JP</given-names></name></person-group><article-title>A Framework For Uncertainty and Validation of 3-D Registration Methods Based On Points and Frames</article-title><source>International Journal of Computer Vision</source><year>1997</year><volume>25</volume><fpage>203</fpage><lpage>229</lpage><pub-id pub-id-type="doi">10.1023/A:1007976002485</pub-id></citation></ref><ref id="B34"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Hill</surname><given-names>DLG</given-names></name><name><surname>Batchelor</surname><given-names>PG</given-names></name><name><surname>Holden</surname><given-names>M</given-names></name><name><surname>Hawkes</surname><given-names>DJ</given-names></name></person-group><article-title>Medical image registration</article-title><source>Phys Med Biol</source><year>2001</year><volume>46</volume><fpage>R1</fpage><lpage>R45</lpage><pub-id pub-id-type="pmid">11277237</pub-id><pub-id pub-id-type="doi">10.1088/0031-9155/46/3/201</pub-id></citation></ref><ref id="B35"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Gee</surname><given-names>JC</given-names></name></person-group><article-title>On matching brain volumes</article-title><source>Pattern Recognition</source><year>1999</year><volume>32</volume><fpage>99</fpage><lpage>111</lpage><pub-id pub-id-type="doi">10.1016/S0031-3203(98)00093-4</pub-id></citation></ref><ref id="B36"><citation citation-type="other"><person-group person-group-type="author"><name><surname>Bajka</surname><given-names>M</given-names></name><name><surname>Berclaz</surname><given-names>G</given-names></name><name><surname>Sch&#x000e4;r</surname><given-names>G</given-names></name></person-group><article-title>Empfehlungen zur Gyn&#x000e4;kologischen Sonographie</article-title><source>SGUMGG &#x02013; Schweizerische Gesellschaft f&#x000fc;r Ultraschall in der Medizin</source><year>1998</year></citation></ref><ref id="B37"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Sch&#x000e4;r</surname><given-names>GN</given-names></name></person-group><article-title>Ultrasonography of the lower urinary tract</article-title><source>Curr Opin Obstet Gynecol</source><year>1997</year><volume>9</volume><fpage>313</fpage><lpage>316</lpage><pub-id pub-id-type="pmid">9360813</pub-id></citation></ref></ref-list></back></article>


